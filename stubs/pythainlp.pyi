from typing import List

def word_tokenize(
    text: str,
) -> List[str]: ...
